import openai
import logging
from aiogram import Bot, Dispatcher, types
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram import Router
from aiogram.filters import Command
from dotenv import load_dotenv
import os
import asyncio

load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = openai.OpenAI(api_key=OPENAI_API_KEY)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(level=logging.INFO)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(storage=MemoryStorage())
router = Router()

PROMPT_TEMPLATE = """
–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ Microsoft Excel –∏ Google –¢–∞–±–ª–∏—Ü–∞–º.
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª –≤–æ–ø—Ä–æ—Å: "{}"
–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ, —è—Å–Ω–æ –∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –ø—Ä–∏–≤–µ–¥–∏ —Ñ–æ—Ä–º—É–ª—ã.
"""

@router.message(Command("start"))
async def start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ Excel –∏ Google –¢–∞–±–ª–∏—Ü–∞–º.\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å —Å–¥–µ–ª–∞—Ç—å, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å!"
    )

@router.message()
async def handle_message(message: types.Message):
    question = message.text.strip()
    prompt = PROMPT_TEMPLATE.format(question)

    await message.answer("ü§î –î—É–º–∞—é...")

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=400
        )
        reply = response.choices[0].message.content.strip()
        await message.answer(reply)
    except Exception as e:
        logging.exception(e)
        await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

async def main():
    dp.include_router(router)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
